\section{Related Work}

\subsection{Academic Systems}
\textbf{Pose Trainer (2020)}~\cite{chen2020pose} applied rule-based analysis of 2D skeletons extracted by OpenPose~\cite{cao2017realtime} to classify exercises such as push-ups and squats.
While effective for offline assessment, the system operates on recorded videos and relies on fixed, hand-crafted thresholds, offering neither real-time corrective feedback nor personalization across users.

\textbf{AIFit (CVPR 2021)}~\cite{fieraru2021aifit} introduced the Fit3D motion-capture dataset and a 3D feedback model capable of joint-level error localization using a deviation parameter ($\eta$) to control critique strictness.
Despite its interpretability, AIFit depends on full-sequence 3D reconstruction (MubyNet) and produces template-based textual feedback after processing entire videos, making it computationally expensive and unsuitable for interactive, real-time coaching.

\textbf{ARFit (IMWUT 2023)}~\cite{mandic2023arfit} incorporated mobile augmented-reality overlays to visualize pose alignment during exercises, demonstrating that spatial feedback can improve motor learning.
However, ARFit primarily focuses on visual guidance and still applies generic thresholds, without providing quantitative analytics such as repetition-level consistency, tempo variation, or joint-wise performance summaries.

\subsection{Commercial Applications}
Commercial fitness applications such as \textbf{Top Pushup}~\cite{toppushup} and \textbf{QuickPose}~\cite{quickpose} have popularized real-time repetition counting using smartphone cameras.
Their feedback is typically binary—labeling repetitions as correct or incorrect—without distinguishing motion quality, temporal stability, or per-joint improvement over time.
Moreover, these systems rely on static, population-level thresholds and simple chatbot-style prompts, offering limited personalization or biomechanically grounded coaching.

\subsection{Pose Stabilization for Real-Time Monocular Systems}
Lightweight pose estimation in monocular RGB videos is known to be sensitive to viewpoint changes,
temporal jitter, and anatomically implausible keypoint distortions.
Prior work has explored \textbf{body-centric canonicalization} to reduce scale and orientation variance by normalizing poses to a canonical reference frame (e.g.,~\cite{shotton2013kinect}),
\textbf{temporal smoothing} to suppress frame-to-frame keypoint noise in interactive systems (e.g., One Euro filter~\cite{casiez2012oneeuro} and Kalman filtering~\cite{welch2006kalman}),
and \textbf{anatomical constraints} to enforce physically plausible limb configurations and reduce ``rubber-limb'' artifacts (e.g.,~\cite{akhter2015pose}).
However, these techniques are often studied in isolation, tuned for specific sensing setups (e.g., depth sensors or calibrated rigs),
or evaluated outside real-time fitness coaching scenarios.
FitCoachAR adapts and integrates these principles into a unified, per-frame post-processing pipeline that operates purely on 2D keypoints
and preserves real-time responsiveness on consumer hardware.

\subsection{Semantic Pose Representation}
Recent work in computer vision has explored bridging geometric pose representations and natural language.
\textbf{PoseScript}~\cite{delmas2022posescript} introduced the concept of \emph{posecodes}—atomic, rule-based boolean descriptors derived from 3D keypoints—to generate synthetic textual descriptions of static human poses.
FitCoachAR adopts a similar architectural philosophy by defining \emph{FormCodes} as a semantic intermediate representation between pose geometry and language.
However, while PoseScript focuses on static pose captioning, our system extends this paradigm to dynamic, temporal motion analysis, using these atomic codes to drive real-time corrective feedback and post-session coaching summaries.


\subsection{Gap Summary}
Across both academic and commercial systems, several limitations remain:
\begin{itemize}
    \item \textbf{Offline or delayed feedback} (Pose Trainer, AIFit).
    \item \textbf{Limited personalization}, with global thresholds or non-user-specific deviation parameters.
    \item \textbf{Shallow analysis}, lacking holistic metrics such as repetition quality, tempo stability, and joint-wise consistency.
    \item \textbf{Limited interactivity}, with little integration of context-aware, natural-language feedback.
\end{itemize}

\textbf{FitCoachAR} addresses these gaps through:
\begin{itemize}
    \item Real-time 2D pose tracking with online processing,
    \item Adaptive deviation sensitivity ($\eta$) for user-specific tolerance,
    \item AR-based spatial feedback for intuitive correction, and
    \item LLM-driven natural coaching for motivating, context-aware guidance.
\end{itemize}

By integrating interpretable pose analysis from AIFit with the usability of mobile AR systems, FitCoachAR enables real-time, personalized exercise coaching on consumer-grade hardware.
