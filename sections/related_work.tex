\section{Related Work}

\subsection{Academic Systems}
\textbf{Pose Trainer (2020)}~\cite{chen2020pose} applied rule-based analysis of 2D skeletons extracted by OpenPose~\cite{cao2017realtime} to classify exercises such as push-ups and squats.
While effective for offline assessment, the system operates on recorded videos and relies on fixed, hand-crafted thresholds, offering neither real-time corrective feedback nor personalization across users.

\textbf{AIFit (CVPR 2021)}~\cite{fieraru2021aifit} introduced the Fit3D motion-capture dataset and a 3D feedback model capable of joint-level error localization using a deviation parameter ($\eta$) to control critique strictness.
Despite its interpretability, AIFit depends on full-sequence 3D reconstruction (MubyNet) and produces template-based textual feedback after processing entire videos, making it computationally expensive and unsuitable for interactive, real-time coaching.

\textbf{ARFit (IMWUT 2023)}~\cite{mandic2023arfit} incorporated mobile augmented-reality overlays to visualize pose alignment during exercises, demonstrating that spatial feedback can improve motor learning.
However, ARFit primarily focuses on visual guidance and still applies generic thresholds, without providing quantitative analytics such as repetition-level consistency, tempo variation, or joint-wise performance summaries.

\subsection{Commercial Applications}
Commercial fitness applications such as \textbf{Top Pushup}~\cite{toppushup} and \textbf{QuickPose}~\cite{quickpose} have popularized real-time repetition counting using smartphone cameras.
Their feedback is typically binary—labeling repetitions as correct or incorrect—without distinguishing motion quality, temporal stability, or per-joint improvement over time.
Moreover, these systems rely on static, population-level thresholds and simple chatbot-style prompts, offering limited personalization or biomechanically grounded coaching.

\subsection{Pose Stabilization for Real-Time Monocular Systems}
Lightweight pose estimation in monocular RGB videos is known to be sensitive to viewpoint changes,
temporal jitter, and anatomically implausible keypoint distortions.
Prior work has explored \textbf{body-centric canonicalization} to reduce scale and orientation variance by normalizing poses to a canonical reference frame (e.g.,~\cite{tang2022gait}),
\textbf{temporal smoothing} to suppress frame-to-frame keypoint noise in interactive systems (e.g., One Euro filter~\cite{casiez2012oneeuro} and Kalman filtering~\cite{welch2006kalman}),
and \textbf{anatomical constraints} to enforce physically plausible limb configurations and reduce ``rubber-limb'' artifacts (e.g.,~\cite{hsu2024accv, chen2021anatomy}).
However, these techniques are often studied in isolation, tuned for specific sensing setups (e.g., depth sensors or calibrated rigs),
or evaluated outside real-time fitness coaching scenarios.
FitCoachAR adapts and integrates these principles into a unified, per-frame post-processing pipeline that operates purely on 2D keypoints
and preserves real-time responsiveness on consumer hardware.

\subsection{Semantic Pose Representation}
Recent work in computer vision has explored bridging geometric pose representations and natural language.
\textbf{PoseScript}~\cite{delmas2022posescript} introduced the concept of \emph{posecodes}—atomic, rule-based boolean descriptors derived from 3D keypoints—to generate synthetic textual descriptions of static human poses.
FitCoachAR adopts a similar architectural philosophy by defining \emph{FormCodes} as a semantic intermediate representation between pose geometry and language.
However, while PoseScript focuses on static pose captioning, our system extends this paradigm to dynamic, temporal motion analysis, using these atomic codes to drive real-time corrective feedback and post-session coaching summaries.


\subsection{Gap Summary}
Despite substantial progress in both academic research and commercial products,
several important gaps remain across the full exercise-coaching pipeline.

\begin{itemize}
    \item \textbf{Lack of real-time, fine-grained feedback.}
    Many academic systems operate offline on recorded videos
    (e.g., Pose Trainer, AIFit),
    while commercial apps focus primarily on repetition counting
    with coarse, binary correctness labels.

    \item \textbf{Limited robustness to viewpoint and scale variation.}
    Most existing systems rely directly on raw 2D or reconstructed 3D poses,
    which are sensitive to camera placement, user orientation,
    and foreshortening effects in monocular RGB videos.
    Techniques such as body-centric normalization, temporal smoothing,
    and anatomical constraints are rarely integrated into real-time fitness applications.

    \item \textbf{Insufficient stability--responsiveness trade-off.}
    While temporal filters and anatomical priors have been studied in isolation,
    they are often tuned for offline analysis or specialized sensors,
    rather than interactive systems where low latency and visual smoothness
    must be jointly optimized.

    \item \textbf{Shallow semantic abstraction.}
    Existing approaches typically map low-level pose measurements
    directly to fixed rules or template messages,
    lacking an intermediate, interpretable representation that can support
    nuanced feedback, temporal reasoning, and natural-language coaching.
\end{itemize}

\textbf{FitCoachAR} addresses these gaps by combining:
\begin{itemize}
    \item real-time 2D pose tracking with lightweight, per-frame post-processing
          for viewpoint robustness and anatomical consistency,
    \item adaptive deviation sensitivity ($\eta$) for user-specific tolerance,
    \item AR-based spatial feedback for intuitive, in-situ correction, and
    \item a semantic pose representation (\emph{FormCodes}) that bridges
          geometric analysis and LLM-driven coaching.
\end{itemize}

This unified design enables stable, interpretable, and interactive exercise feedback
on consumer-grade hardware, bridging low-level pose processing and high-level coaching intelligence.
