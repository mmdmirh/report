\section{Evaluation Plan}
\paragraph{Metrics and targets}
\begin{itemize}
    \item Segmentation IoU: overlap of detected vs. manual rep boundaries; target $\ge 0.70$.
    \item Latency: end-to-end delay (camera $\rightarrow$ feedback); target $< 100$ ms.
    \item Error detection F1: accuracy of error detection vs. labeled data; target $> 0.80$.
    \item User study: 5 participants rate clarity and usefulness (1–5 Likert); target $\ge 4.0$ average.
    \item Personalization gain: precision improvement after calibration; target $+10\%$.
    \item Summary usefulness: user rating of LLM feedback (1–5 Likert); target $\ge 4.2$ average.
    \item Summary relevance: expert validation of LLM feedback vs. video review; target $\ge 85\%$.
\end{itemize}

\paragraph{Evaluation will use:}
\begin{itemize}
    \item Fit3D dataset — for offline benchmarking of segmentation and feature thresholds.
    \item Self-recorded data — for calibration and real-time tests.
\end{itemize}
